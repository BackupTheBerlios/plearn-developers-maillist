From delallea at iro.umontreal.ca  Fri Sep  9 16:08:13 2005
From: delallea at iro.umontreal.ca (Olivier Delalleau)
Date: Fri, 9 Sep 2005 10:08:13 -0400
Subject: [Plearn-developers] Boost upgrade to 1.33.0 at LISA lab
Message-ID: <20050909140813.GA19643@lsvm.iro.umontreal.ca>

For compatibility with gcc 4.0.1, I upgraded the Boost library at LISA
to the latest version (1.33.0). Please tell me if you notice anything
going wrong.

--
Olivier



From delallea at iro.umontreal.ca  Sat Sep 10 01:39:05 2005
From: delallea at iro.umontreal.ca (Olivier Delalleau)
Date: Fri, 9 Sep 2005 19:39:05 -0400
Subject: [Plearn-developers] Boost upgrade to 1.33.0 at LISA lab
In-Reply-To: <20050909140813.GA19643@lsvm.iro.umontreal.ca>
References: <20050909140813.GA19643@lsvm.iro.umontreal.ca>
Message-ID: <20050909233905.GA27738@lsvm.iro.umontreal.ca>

Note also that if you encounter some linking errors, you may need to
clean your old object files. For this, do for instance
    pymake -clean .
in your home directory, or in any directory containing some compiled
objects.
In addition, it looks like there are still some linking problems when
compiling in 64 bits, so better stick with the -m32 flag until this is
fixed.

--
Olivier

On 09 Sep 2005, Olivier Delalleau wrote:
> For compatibility with gcc 4.0.1, I upgraded the Boost library at LISA
> to the latest version (1.33.0). Please tell me if you notice anything
> going wrong.
> 


From delallea at iro.umontreal.ca  Mon Sep 12 17:20:26 2005
From: delallea at iro.umontreal.ca (Olivier Delalleau)
Date: Mon, 12 Sep 2005 11:20:26 -0400
Subject: [Plearn-developers] Boost upgrade to 1.33.0 at LISA lab
In-Reply-To: <20050909233905.GA27738@lsvm.iro.umontreal.ca>
References: <20050909140813.GA19643@lsvm.iro.umontreal.ca> <20050909233905.GA27738@lsvm.iro.umontreal.ca>
Message-ID: <20050912152026.GA15965@lsvm.iro.umontreal.ca>

Linking on 64 bits computers (and, hopefully, any other LISA computer)
should now be ok.
If you are NOT including /u/lisa/.local.cshrc in your .cshrc (or
/u/lisa/local/.bashrc in your .bashrc), you should set the LIBRARY_PATH
environment variable just like in those files.

--
Olivier

On 09 Sep 2005, Olivier Delalleau wrote:
> In addition, it looks like there are still some linking problems when
> compiling in 64 bits, so better stick with the -m32 flag until this is
> fixed.
> 


From delallea at iro.umontreal.ca  Fri Sep 23 16:57:07 2005
From: delallea at iro.umontreal.ca (Olivier Delalleau)
Date: Fri, 23 Sep 2005 10:57:07 -0400
Subject: [Plearn-developers] PLearn compilation @ LISA
Message-ID: <20050923145706.GA13566@lsvm.iro.umontreal.ca>

Dear all (= three) users of PLearn @ Lisa,

Ce qui me fait penser que je peux continuer en fran?ais.
Suite au passage ? Fedora Core 4, il y a quelques petits soucis de
compilation / link, qui sont en train de se r?soudre progressivement
(pour l'instant, la compilation 64 bits fonctionne).
Par contre, par s?curit?, je d?conseillerais d'utiliser les machines du
cluster pour la compilation, car elles n'ont pas encore ?t? mises ?
jour, et n'ont pas la m?me version de gcc.
Vu qu'apr?s mise ? jour, rsh n'est plus accept?, pymake utilise
maintenant ssh pour lancer les compilations ? distance. Ca veut dire que
vous devez vous connecter en ssh ? chacune des machines dans votre liste
(dans le ~/.pymake/...hosts) et accepter leur cl?, sinon la compilation
va bloquer.

--
Olivier



From chapados at apstat.com  Wed Sep 28 19:00:21 2005
From: chapados at apstat.com (Nicolas Chapados)
Date: Wed, 28 Sep 2005 13:00:21 -0400
Subject: [Plearn-developers] Tight bridge between Python and C++/PLearn (experimental)
Message-ID: <433ACC25.90807@apstat.com>

Hello all PLearners,

Please answer, in complete honesty and privacy, the following questions:

    * /*When writing a PLearn script, have you ever been faced with a
      data matrix in a "slightly wrong" format, and wished there were a
      VMatrix type that could do "just this tiny little thing"?*/
    * /*Ever faced the prospect of trying to understand SOMEONE ELSE's
      VPL (VMatrix Processing Language) code?*/
    * /*Ever wished to write a PLearn class that you could INHERIT FROM
      IN PYTHON?*/


*  *  *  *  *  *

/*Today, m*//*y friend, your wishes have come true.*/

*  *  *  *  *  *

I just committed to SVN a set of (still-experimental) classes that 
constitute the elements of a tight bridge between Python and 
C++/PLearn.  By "tight bridge", I mean that both PLearn and the Python 
interpreter are linked together and live in the same process.  With this 
bridge, you can write Python code in the form of "code snippets" that 
implement pieces of functionality that are integrated at runtime into 
PLearn.  An example of this is the new PythonProcessedVMatrix, which 
provides the same functionality as ProcessingVMatrix (and more!), but 
using Python code instead of VPL.  An example of a very simple .pymat 
script is as follows (see 
PLearn/plearn/python/test/test_python_vmatrix.pymat) ::

    from plearn.pyplearn import *

    source_mat = pl.MemoryVMatrix(
        data = TMat(4, 2, [ 2, 3,
                            5, 7,
                            11,13,
                            17,19 ]),
        inputsize = 1, targetsize = 1, weightsize = 0)

    processing_code = """
    from numarray import *

    def getRow(row_no, source_row):
        return concatenate((10*row_no, 2*source_row))

    def getFieldNames(source_field_names):
        return ['tricky_rownum', 'field1', 'field2']
    """
                   
    processed_mat = pl.PythonProcessedVMatrix(
        source = source_mat,
        code = processing_code)
       

    def main():
        return processed_mat

This script operates as follows:

   1. It starts by defining a source VMatrix that contains the
      underlying data to transform (just a simple inline matrix in this
      example)
   2. Then it defines the Python code snippet that will be used to
      process the source VMatrix rows.  This is the code "injected" into
      the running PLearn process.  The snippet must define at least two
      functions (more can be defined by the interface -- see the
      documentation for PythonProcessedVMatrix) ::
          * getRow() returns a processed row given a source row
          * getFieldNames returns the NEW fieldnames given the source
            field names
   3. Finally, everything is wrapped into the PythonProcessedVMatrix,
      which links all pieces and provides the VMatrix interface.
   4. You now just have to do a "plearn vmat view" on this file to see
      the result!

NOTE: do not confuse the "outer Python" with the "inner Python"!  The 
outer-level .pymat script is itself Python code, but is used strictly as 
a preprocessor to generate a .plearn script for the PLearn program.  The 
inner-level processing_code is Python code that is injected into the 
running PLearn process through the PythonProcessedVMatrix.

*  *  *  *  *  *

If you peek under the hood, you will discover a set of new classes, the 
most important being PythonObjectWrapper and PythonCodeSnippet.  The 
first one is a lightweight C++ wrapper around the fundamental Python 
objects, the PyObject*.  It provides such niceties as automatic and 
type-safe conversion between (some) C++ and Python types, as well as 
managing the Python reference counts.

The second one, PythonCodeSnippet, actually handles the calling of 
Python code from C++.  This object is designed to be *embedded* within 
client C++ code (in the example above, PythonProcessedVMatrix) and 
handles the compilation of the snippet, the translation between C++ 
function calls and Python calls (arguments and return values).  It also 
support the *injection of C++ callbacks into Python*, in order to 
provide the PythonCodeSnippet with a well-defined interface to the main 
PLearn C++ core. Finally, it provides an optional mapping between Python 
Exceptions and C++ Exceptions.

The class PythonProcessedVMatrix is but one example of what is 
possible.  We can imagine pre/post-processing functionality for 
PLearner, PLearners themselves written in Python, etc.  I also envision 
a more complete eventual bridge, wherein Python snippets will be able to 
instantiate, manipulate and return /bona fide/ PLearn objects.

*  *  *  *  *  *

*Frequently Asked Questions*

Q1: /"I tried your example but it doesn't work."  (Bob, Louisiana)/
A1: You need to perform the following steps:

    * svn update of PLearn
    * Uncomment two lines in the "plearn_inc.h" file.  These lines are
      the #include directives for PythonCodeSnippet.h and
      PythonProcessedVMatrix.h.  *(I left them commented out at the
      moment since I consider this bridge to be still-experimental)*
    * Ensure that the Python settings in the PLearn/python.config.model
      file are adequate for your environment.
    * Recompile PLearn
    * Try again "plearn vmat view test_python_vmatrix.pymat"


Q2: /"I'm trying to instantiate a PythonCodeSnippet from a script. Now 
what?"  (Rick, Michigan)/
A2: The PythonCodeSnippet is not designed to be instantiated directly 
from a script, but to be contained within an embedding PLearn class, for 
instance PythonProcessedVMatrix.  It is the embedding class that defines 
its own requirements for what the snippet looks like (i.e. what 
functions must the snippet define) and in turn what API the snippet has 
access to (in the form of global variables and injected C++ callbacks).

Q3: /"PLearn does not compile anymore with that Python stuff enabled!" 
(Bill, Missouri)/
A3: You must have the following libraries properly installed:

    * The Python core libraries and include files (libpython)
    * The Numarray library (it's a Python package; PLearn's Vec and Mat
      are mapped to numarray objects) and include files
    * The Boost library (probably at least 1.32)

The version of Python to use (2.3 or 2.4) can be specifed with a 
compile-time define.  See the file <plearn/python/PythonIncludes.h>

Q4: /"Can the Python snippet keep state between function calls?" 
(George, Texas)/
A4: Yes, each snippet operates in its own private environment with its 
own set of global variables.  Just declare "global xyz" at the start of 
a function, and the variable xyz will be maintained across calls to 
functions within the snippet and can be used by all the functions of the 
snippet.

Q5: /"Can several Python snippets communicate with one another?" (Patty, 
California)/
A5: Not directly. Each snippet operates in its own environment, with its 
own set of functions and global variables.  This means that two snippet 
cannot accidentally interfere (define two functions of the same name but 
with different purposes).  But it also means that communication between 
snippets is more difficult.  One possibility is to make use of 
mechanisms that are SHARED across the snippets, such as Python modules.  
For example, two snippets could communicate using a common module known 
to those two only.  (This has not been tested yet).

*  *  *  *  *  *

As always, comments and suggestions welcome!

    Enjoy!
    Nicolas (Montr?al, Qu?bec)

-- 
Nicolas Chapados, M.Sc.
ApSTAT Technologies Inc.
www.apstat.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/plearn-developers/attachments/20050928/dcdf2605/attachment.html>

